{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0    happy  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "1    angry  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "2    angry  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "3    happy  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "4    angry  /home/sedunov_ia/project_mtl/multitask_learnin..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ravdess = \"/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/ravdess/\"\n",
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "for dir in ravdess_directory_list:\n",
    "    # as their are 20 different actors in our previous directory we need to extract files for each actor.\n",
    "    actor = os.listdir(Ravdess + dir)\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        # third part in each file represents the emotion associated to that file.\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(Ravdess + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "# changing integers to actual emotions.\n",
    "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Ravdess_df['Emotions'].hist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crema D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crema = \"/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/cremad/AudioWAV/\"\n",
    "crema_directory_list = os.listdir(Crema)\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0  neutral  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "1  neutral  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "2  neutral  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "3  neutral  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "4  neutral  /home/sedunov_ia/project_mtl/multitask_learnin..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tess = \"/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\n",
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Tess_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0    happy  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "1      sad  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "2  neutral  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "3      sad  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "4  disgust  /home/sedunov_ia/project_mtl/multitask_learnin..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "Savee = \"/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/savee/audiodata/AudioData/\"\n",
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "files_paths = glob.glob(\"/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/savee/audiodata/AudioData/*/*.wav\")\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in files_paths:\n",
    "    file_path.append(file)\n",
    "    base_name = os.path.basename(file)\n",
    "    if base_name.startswith('a'):\n",
    "        file_emotion.append('angry')\n",
    "    elif base_name.startswith('d'):\n",
    "        file_emotion.append('disgust')\n",
    "    elif base_name.startswith('f'):\n",
    "        file_emotion.append('fear')\n",
    "    elif base_name.startswith('h'):\n",
    "        file_emotion.append('happy')\n",
    "    elif base_name.startswith('n'):\n",
    "        file_emotion.append('neutral')\n",
    "    elif base_name.startswith('sa'):\n",
    "        file_emotion.append('sad')\n",
    "    else:\n",
    "        file_emotion.append('surprise')\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Savee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>/home/sedunov_ia/project_mtl/multitask_learnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                                               Path\n",
       "0    happy  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "1    angry  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "2    angry  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "3    happy  /home/sedunov_ia/project_mtl/multitask_learnin...\n",
       "4    angry  /home/sedunov_ia/project_mtl/multitask_learnin..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Dataframe using all the 4 dataframes we created so far.\n",
    "data_path = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path.loc[data_path.Emotions == 'calm', 'Emotions'] = 'neutral'\n",
    "data_path.loc[data_path.Emotions == 'surprise', 'Emotions'] = 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path['Emotions'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path.to_csv(\"/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/emo_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = pd.read_csv(\"/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/emo_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path['emotions'] = data_path['Emotions']\n",
    "data_path['label'], _ = pd.factorize(data_path['emotions'])\n",
    "data_path['wav'] = data_path['Path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11734"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(data_path[['wav', 'label', 'emotions']], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/train_emo_en.csv', index=False, sep='|')\n",
    "df_test.to_csv('/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/test_emo_en.csv', index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['neutral', 'fear', 'happy', 'angry', 'disgust', 'sad'],\n",
       "       dtype=object),\n",
       " array(['disgust', 'neutral', 'happy', 'angry', 'fear', 'sad'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['emotions'].unique(), df_test['emotions'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS.wav\"[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11734it [57:43,  3.39it/s] \n"
     ]
    }
   ],
   "source": [
    "import torchaudio, os\n",
    "import torchaudio.transforms as T\n",
    "from tqdm import tqdm\n",
    "dst_fld = \"/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/data_emo_resampled/audio\"\n",
    "records = []\n",
    "not_mono = []\n",
    "for _, row in tqdm(data_path.iterrows()):\n",
    "    wav, sr = torchaudio.load(row['wav'])\n",
    "    if len(wav.size()) > 2:\n",
    "        print(\"not mono\")\n",
    "        not_mono.append(row['wav'])\n",
    "        continue\n",
    "    dur = wav.size()[1]/sr\n",
    "    dst_path = row['wav']\n",
    "    if sr != 16000:\n",
    "        base_name = os.path.basename(row['wav'])\n",
    "        dst_path = os.path.join(dst_fld, f\"{base_name[:-4]}_resampled.wav\")\n",
    "        wav = T.Resample(orig_freq=sr, new_freq=16000)(wav)\n",
    "        torchaudio.save(dst_path, wav, 16000)\n",
    "    records.append({\n",
    "        'wav': dst_path, 'label': row['label'], 'emotions': row['emotions'], 'dur': dur, 'init_sr': sr\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_rec_resampled = pd.DataFrame().from_records(records)\n",
    "\n",
    "df_train, df_test = train_test_split(df_rec_resampled, test_size=0.2, random_state=42)\n",
    "df_train.to_csv('/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/train_emo_en_resampled.csv', index=False, sep='|')\n",
    "df_test.to_csv('/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/data/test_emo_en_resampled.csv', index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/sedunov_ia/project_mtl/multitask_learning_ASR_KWS/other/train_kws.csv')\n",
    "len(df.keyword.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dusha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('/home/sedunov_ia/emotion_recognition/data_dusha_and_prev_emo_35k_per_class/train_before_gsm.csv', sep='|')\n",
    "df_test = pd.read_csv('/home/sedunov_ia/emotion_recognition/data_dusha_and_prev_emo_35k_per_class/test_before_gsm.csv', sep='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample = df_train.sample(20000)\n",
    "df_train_sample.to_csv('/home/sedunov_ia/emotion_recognition/data_dusha_and_prev_emo_35k_per_class/train_before_gsm_sample.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sample = df_train.sample(9000)\n",
    "df_test_sample.to_csv('/home/sedunov_ia/emotion_recognition/data_dusha_and_prev_emo_35k_per_class/test_before_gsm_sample.csv', sep='|', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
